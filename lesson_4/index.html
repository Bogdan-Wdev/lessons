<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css?family=Kalam:300,regular,700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/reset.css">
    <link rel="stylesheet" href="css/style.css">

    <title>lesson 4

    </title>
</head>

<body>
    <header class="header">
        <div class="logo">ChatGPT</div>
        <ul class="menu">
            <li class="item">
                <a href="#t1">Intro</a>
            </li>
            <li class="item">
                <a href="#t2">Training</a>
            </li>
            <li class="item">
                <a href="#t3">Features and limitations</a>
            </li>
            <li class="item">
                <a href="#t4">Service</a>
            </li>
            <li class="item">
                <a href="#t5">Reception</a>
            </li>
            <li class="item">
                <a href="#t6">Implications</a>
            </li>
            <li class="item">
                <a href="#t7">Ethical concerns</a>
            </li>
            <li class="item">
                <a href="#t8">Competition</a>
            </li>

        </ul>
    </header>
    <main class="main">
        <div class="block">
            <h2 id="t1" class="title">Intro</h2>
            <p class="text">ChatGPT (Chat Generative Pre-trained Transformer)[2] is  a chatbot developed by OpenAI and <br>
                launched in November 2022. It is built on top of OpenAI's GPT-3 family of large language models and has <br>
                been
                fine-tuned (an approach to transfer learning)[3] using both supervised and  reinforcement learning <br>
                techniques.
                ChatGPT was launched as a prototype on November 30, 2022, and quickly garnered attention for its <br>
                detailed
                responses and articulate answers across many domains of knowledge. Its uneven factual accuracy, however,<br>
                was
                identified as a significant drawback.[4] Following the release of ChatGPT, OpenAI's valuation was <br>
                estimated
                at US$29 billion.[5]
            </p>
        </div>
        <div class="block">
            <h2 id="t2" class="title">Training</h2>
            <p class="text">ChatGPT – a generative pre-trained transformer (GPT) – was fine-tuned on top of GPT-3.5<br>
                using supervised learning as well as reinforcement learning.[6] Both approaches used human trainers to<br>
                improve the model's performance. In the case of supervised learning, the model was provided with<br>
                conversations in which the trainers played both sides: the user and the AI assistant. In the<br>
                reinforcement step, human trainers first ranked responses that the model had created in a previous<br>
                conversation. These rankings were used to create 'reward models' that the model was further fine-tuned<br>
                on using several iterations of Proximal Policy Optimization (PPO).[7][8] Proximal Policy Optimization<br>
                algorithms present a cost-effective benefit to trust region policy optimization algorithms; they negate<br>
                many of the computationally expensive operations with faster performance.[9][10] The models were trained<br>
                in collaboration with Microsoft on their Azure supercomputing infrastructure.
            </p>
            <p class="text">In addition, OpenAI continues to gather data from ChatGPT users that could be used to<br>
                further train and fine-tune ChatGPT. Users are allowed to upvote or downvote the responses they receive<br>
                from ChatGPT; upon upvoting or downvoting, they can also fill out a text field with additional feedback.<br>
            </p>
        </div>
        <div class="block">
            <h2 id="t3" class="title">Features and limitations</h2>
            <p class="text">Although the core function of a chatbot is to mimic a human conversationalist, ChatGPT is
                versatile. For example, it can write and debug computer programs,[13] compose music, teleplays, fairy
                tales, and student essays; answer test questions (sometimes, depending on the test, at a level above the
                average human test-taker);[14] write poetry and song lyrics;[15] emulate a Linux system; simulate an
                entire chat room; play games like tic-tac-toe; and simulate an ATM.[16] ChatGPT's training data includes
                man pages and information about Internet phenomena and programming languages, such as bulletin board
                systems and the Python programming language.[16]
            </p>
            <p class="text">In comparison to its predecessor, InstructGPT, ChatGPT attempts to reduce harmful and
                deceitful responses.[17] In one example, whereas InstructGPT accepts the premise of the prompt "Tell me
                about when Christopher Columbus came to the U.S. in 2015" as being truthful, ChatGPT acknowledges the
                counterfactual nature of the question and frames its answer as a hypothetical consideration of what
                might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher
                Columbus and facts about the modern world – including modern perceptions of Columbus' actions.[7]

                Unlike most chatbots, ChatGPT remembers previous prompts given to it in the same conversation;
                journalists have suggested that this will allow ChatGPT to be used as a personalized therapist.[2] To
                prevent offensive outputs from being presented to and produced from ChatGPT, queries are filtered
                through OpenAI's company-wide moderation API,[18][19] and potentially racist or sexist prompts are
                dismissed
            </p>
            <p class="text">ChatGPT suffers from multiple limitations. OpenAI acknowledged that ChatGPT "sometimes
                writes plausible-sounding but incorrect or nonsensical answers".[7] This behavior is common to large
                language models and is called artificial intelligence hallucination.[20] The reward model of ChatGPT,
                designed around human oversight, can be over-optimized and thus hinder performance, otherwise known as
                Goodhart's law.[21] ChatGPT has limited knowledge of events that occurred after 2021. According to the
                BBC, as of December 2022, ChatGPT is not allowed to "express political opinions or engage in political
                activism".[22] Yet, research suggests that ChatGPT exhibits a pro-environmental, left-libertarian
                orientation when prompted to take a stance on political statements from two established voting advice
                applications.[23] In training ChatGPT, human reviewers preferred longer answers, irrespective of actual
                comprehension or factual content.[7] Training data also suffers from algorithmic bias, which may be
                revealed when ChatGPT responds to prompts including descriptors of people. In one instance, ChatGPT
                generated a rap indicating that women and scientists of color were inferior to white and male
                scientists.[24][25]
            </p>
        </div>
        <div class="block">
            <h2 id="t4" class="title">Service</h2>
            <p class="text">ChatGPT was launched on November 30, 2022, by San Francisco–based OpenAI, the creator of
                DALL·E 2 and Whisper AI. The service was launched as initially free to the public, with plans to
                monetize the service later.[26] By December 4, OpenAI estimated ChatGPT already had over one million
                users.[11] In January 2023, ChatGPT reached over 100 million users, making it the fastest growing
                consumer application to date.[27] CNBC wrote on December 15, 2022, that the service "still goes down
                from time to time".[28] The service works best in English, but is also able to function in some other
                languages, to varying degrees of success.[15] Unlike some other recent high-profile advances in AI, as
                of December 2022, there is no sign of an official peer-reviewed technical paper about ChatGPT.[29]
            </p>
            <p class="text">According to OpenAI guest researcher Scott Aaronson, OpenAI is working on a tool to attempt
                to digitally watermark its text generation systems to combat bad actors using their services for
                academic plagiarism or spam.[30][31] The company says that this tool, called "AI classifier for
                indicating AI-written text",[32] will "likely yield a lot of false positives and negatives, sometimes
                with great confidence." An example cited in The Atlantic magazine showed that "when given the first
                lines of the Book of Genesis, the software concluded that it was likely to be AI-generated."[33]
                The New York Times reported in December 2022 that it has been "rumored" that the next version of the AI,
                GPT-4, will be launched sometime in 2023.[2] In February 2023, OpenAI began accepting registrations from
                United States customers for a premium service, ChatGPT Plus, to cost $20 a month.[34] OpenAI is planning
                to release a ChatGPT Professional Plan that costs $42 per month, and the free plan is available when
                demand is low.
            </p>
        </div>
        <div class="block">
            <h2 id="t5" class="title">Reception</h2>
            <h3 class="subtitle green">Positive</h3>
            <p class="text">ChatGPT was met in December 2022 with some positive reviews; Kevin Roose of The New York
                Times labeled it "the best artificial intelligence chatbot ever released to the general public".[2]
                Samantha Lock of The Guardian newspaper noted that it was able to generate "impressively detailed" and
                "human-like" text.[35] Technology writer Dan Gillmor used ChatGPT on a student assignment, and found its
                generated text was on par with what a good student would deliver and opined that "academia has some very
                serious issues to confront".[36] Alex Kantrowitz of Slate magazine lauded ChatGPT's pushback to
                questions related to Nazi Germany, including the statement that Adolf Hitler built highways in Germany,
                which was met with information regarding Nazi Germany's use of forced labor.[37]
                In The Atlantic magazine's "Breakthroughs of the Year" for 2022, Derek Thompson included ChatGPT as part
                of "the generative-AI eruption" that "may change our mind about how we work, how we think, and what
                human creativity really is".[38]
            </p>
            <p class="text">Kelsey Piper of the Vox website wrote that "ChatGPT is the general public's first hands-on
                introduction to how powerful modern AI has gotten, and as a result, many of us are [stunned]" and that
                ChatGPT is "smart enough to be useful despite its flaws".[39] Paul Graham of Y Combinator tweeted that
                "The striking thing about the reaction to ChatGPT is not just the number of people who are blown away by
                it, but who they are. These are not people who get excited by every shiny new thing. Clearly, something
                big is happening."[40] Elon Musk wrote that "ChatGPT is scary good. We are not far from dangerously
                strong AI".[39] Musk paused OpenAI's access to a Twitter database pending a better understanding of
                OpenAI's plans, stating that "OpenAI was started as open source and nonprofit. Neither is still
                true."[41][42] Musk had co-founded OpenAI in 2015, in part to address existential risk from artificial
                intelligence, but had resigned in 2018.[42]
            </p>
            <p class="text">In December 2022, Google internally expressed alarm at the unexpected strength of ChatGPT
                and the newly discovered potential of large language models to disrupt the search engine business, and
                CEO Sundar Pichai "upended" and reassigned teams within multiple departments to aid in its artificial
                intelligence products, according to a report in The New York Times.[43] The Information website reported
                on January 3, 2023, that Microsoft Bing was planning to add optional ChatGPT functionality into its
                public search engine, possibly around March 2023.[44][45] According to CNBC reports, Google employees
                are intensively testing a chatbot called "Apprentice Bard", and Google is preparing to use this
                "apprentice" to compete with ChatGPT.[46]
                Stuart Cobbe, a chartered accountant in England and Wales, decided to test ChatGPT by entering questions
                from a sample exam paper on the ICAEW website and then entering its answers back into the online test.
                ChatGPT scored 42 percent, which, while below the 55 percent pass mark, was considered a reasonable
                attempt.[47]
            </p>
            <p class="text">Writing in Inside Higher Ed professor Steven Mintz states that he "consider[s] ChatGPT ...
                an ally, not an adversary." He went on to say that he felt the AI could assist educational goals by
                doing such things as making reference lists, generating "first drafts", solving equations, debugging,
                and tutoring. In the same piece, he also writes:[48]
                I'm well aware of ChatGPT's limitations. That it's unhelpful on topics with fewer than 10,000 citations.
                That factual references are sometimes false. That its ability to cite sources accurately is very
                limited. That the strength of its responses diminishes rapidly after only a couple of paragraphs. That
                ChatGPT lacks ethics and can't currently rank sites for reliability, quality, or trustworthiness.
                OpenAI CEO Sam Altman was quoted in The New York Times as saying that AI's "benefits for humankind could
                be 'so unbelievably good that it's hard for me to even imagine.' (He has also said that in a worst-case
                scenario, A.I. could kill us all.)"[49]
            </p>
            <h3 class="subtitle red">Negative</h3>
            <p class="text">In the months since its release, ChatGPT has been met with widespread criticism from
                educators, journalists, artists, ethicists, academics, and public advocates. James Vincent of The Verge
                website saw the viral success of ChatGPT as evidence that artificial intelligence had gone
                mainstream.[8] Journalists have commented on ChatGPT's tendency to "hallucinate."[50] Mike Pearl of the
                online technology blog Mashable tested ChatGPT with multiple questions. In one example, he asked ChatGPT
                for "the largest country in Central America that isn't Mexico." ChatGPT responded with Guatemala, when
                the answer is instead Nicaragua.[51] When CNBC asked ChatGPT for the lyrics to "The Ballad of Dwight
                Fry," ChatGPT supplied invented lyrics rather than the actual lyrics.[28] Researchers cited by The Verge
                compared ChatGPT to a "stochastic parrot",[52] as did Professor Anton Van Den Hengel of the Australian
                Institute for Machine Learning.[53]
                In December 2022, the question and answer website Stack Overflow banned the use of ChatGPT for
                generating answers to questions, citing the factually ambiguous nature of ChatGPT's responses.[4] In
                January 2023, the International Conference on Machine Learning banned any undocumented use of ChatGPT or
                other large language models to generate any text in submitted papers.[54]
            </p>
            <p class="text">Economist Tyler Cowen expressed concerns regarding its effects on democracy, citing its
                ability to produce automated comments, which could affect the decision process for new regulations.[55]
                An editor at The Guardian, a British newspaper, questioned whether any content found on the Internet
                after ChatGPT's release "can be truly trusted" and called for government regulation.[56]
                In January 2023, after being sent a song written by ChatGPT in the style of Nick Cave,[57] the
                songwriter himself responded on The Red Hand Files[58] (and was later quoted in The Guardian) saying the
                act of writing a song is "a blood and guts business ... that requires something of me to initiate the
                new and fresh idea. It requires my humanness." He went on to say, "With all the love and respect in the
                world, this song is bullshit, a grotesque mockery of what it is to be human, and, well, I don't much
                like it."[57][59]
                In 2023, Australian MP Julian Hill advised the national parliament that the growth of AI could cause
                "mass destruction". During his speech, which was partly written by the program, he warned that it could
                result in cheating, job losses, discrimination, disinformation, and uncontrollable military
                applications.[60]
            </p>
        </div>
        <div class="block">
            <h2 id="t6" class="title">Implications</h2>
            <h3 class="subtitle">In cybersecurity</h3>
            <p class="text">Check Point Research and others noted that ChatGPT was capable of writing phishing emails
                and malware, especially when combined with OpenAI Codex.[61] OpenAI CEO Sam Altman wrote that advancing
                software could pose "(for example) a huge cybersecurity risk" and also continued to predict "we could
                get to real AGI (artificial general intelligence) in the next decade, so we have to take the risk of
                that extremely seriously". Altman argued that, while ChatGPT is "obviously not close to AGI", one should
                "trust the exponential. Flat looking backwards, vertical looking forwards."[11]
            </p>
            <h3 class="subtitle">In academia</h3>
            <p class="text">ChatGPT can write introduction and abstract sections of scientific articles, which raises
                ethical questions.[62] Several papers have already listed ChatGPT as co-author.[63]
                In The Atlantic magazine, Stephen Marche noted that its effect on academia and especially application
                essays is yet to be understood.[64] California high school teacher and author Daniel Herman wrote that
                ChatGPT would usher in "the end of high school English".[65] In the Nature journal, Chris Stokel-Walker
                pointed out that teachers should be concerned about students using ChatGPT to outsource their writing,
                but that education providers will adapt to enhance critical thinking or reasoning.[66] Emma Bowman with
                NPR wrote of the danger of students plagiarizing through an AI tool that may output biased or
                nonsensical text with an authoritative tone: "There are still many cases where you ask it a question and
                it'll give you a very impressive-sounding answer that's just dead wrong."[67]
            </p>
            <p class="text"> Joanna Stern with The Wall Street Journal described cheating in American high school
                English with the tool
                by submitting a generated essay.[68] Professor Darren Hick of Furman University described noticing
                ChatGPT's
                "style" in a paper submitted by a student. An online GPT detector claimed the paper was 99.9 percent
                likely
                to be computer-generated, but Hick had no hard proof. However, the student in question confessed to
                using
                GPT when confronted, and as a consequence failed the course.[69] Hick suggested a policy of giving an
                ad-hoc
                individual oral exam on the paper topic if a student is strongly suspected of submitting an AI-generated
                paper.[70] Edward Tian, a senior undergraduate student at Princeton University, created a program, named
                "GPTZero," that determines how much of a text is AI-generated,[71] lending itself to being used to
                detect if
                an essay is human written to combat academic plagiarism.[72][73]
                As of January 4, 2023, the New York City Department of Education has restricted access to ChatGPT from
                its
                public school internet and devices.[74][75]
                In a blinded test, ChatGPT was judged to have passed graduate-level exams at the University of Minnesota
                at
                the level of a C+ student and at Wharton School of the University of Pennsylvania with a B to B-
                grade.[76]
            </p>
        </div>
        <div class="block">
            <h2 id="t7" class="title">Ethical concerns</h2>
            <h3 class="subtitle">Labeling data</h3>
            <p class="text">It was revealed by a TIME magazine investigation that to build a safety system against toxic
                content (e.g. sexual abuse, violence, racism, sexism, etc. ...), OpenAI used outsourced Kenyan workers
                earning less than $2 per hour to label toxic content. These labels were used to train a model to detect
                such content in the future. The outsourced laborers were exposed to such toxic and dangerous content
                that they described the experience as "torture".[77] OpenAI's outsourcing partner was Sama, a
                training-data company based in San Francisco, California.
            </p>
            <h3 class="subtitle">Jailbreaking</h3>
            <p class="text">ChatGPT attempts to reject prompts that may violate its content policy. However, some users
                managed to jailbreak ChatGPT by using various prompt engineering techniques to bypass these restrictions
                in early December 2022 and successfully tricked ChatGPT into giving instructions for how to create a
                Molotov cocktail or a nuclear bomb, or into generating arguments in the style of a neo-Nazi.[78] A
                Toronto Star reporter had uneven personal success in getting ChatGPT to make inflammatory statements
                shortly after launch: ChatGPT was tricked to endorse the 2022 Russian invasion of Ukraine, but even when
                asked to play along with a fictional scenario, ChatGPT balked at generating arguments for why Canadian
                Prime Minister Justin Trudeau was guilty of treason.[79][80]
            </p>
        </div>
        <div class="block">
            <h2 id="t8" class="title">Competition</h2>
            <p class="text">ChatGPT attempts to reject prompts that may violate its content policy. However, some users
                managed to jailbreak ChatGPT by using various prompt engineering techniques to bypass these restrictions
                in early December 2022 and successfully tricked ChatGPT into giving instructions for how to create a
                Molotov cocktail or a nuclear bomb, or into generating arguments in the style of a neo-Nazi.[78] A
                Toronto Star reporter had uneven personal success in getting ChatGPT to make inflammatory statements
                shortly after launch: ChatGPT was tricked to endorse the 2022 Russian invasion of Ukraine, but even when
                asked to play along with a fictional scenario, ChatGPT balked at generating arguments for why Canadian
                Prime Minister Justin Trudeau was guilty of treason.[79][80]
            </p>
        </div>
    </main>
    <footer class="footer">
        <a href="#">One more time</a>
    </footer>
</body>

</html>
